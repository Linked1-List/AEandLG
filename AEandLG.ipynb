{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Linked1-List/AEandLG/blob/main/AEandLG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BM24AUdlEKFQ"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lvgMemU_5Fcf",
        "outputId": "1acdfa91-5316-4c03-8603-bf1869a158b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ATeQ15JBEMxy",
        "outputId": "b734a4d0-a340-4918-905c-93a667a7daac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "총 203개의 청크가 /content/drive/MyDrive/humanchunk 디렉토리에 저장되었습니다.\n"
          ]
        }
      ],
      "source": [
        "import librosa\n",
        "import os\n",
        "import soundfile as sf\n",
        "\n",
        "# 음성 파일을 로드하는 함수\n",
        "def load_audio(file_path, target_sr=16000):\n",
        "    audio, sr = librosa.load(file_path, sr=target_sr)\n",
        "    return audio, sr\n",
        "\n",
        "# 음성을 청크로 나누는 함수\n",
        "def split_audio(audio, sr, chunk_length_sec=5, output_dir='output_audio'):\n",
        "    # chunk 길이를 샘플로 변환 (초 -> 샘플)\n",
        "    chunk_length_samples = chunk_length_sec * sr\n",
        "\n",
        "    # 저장할 디렉토리 생성 (없으면)\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    # 청크로 나누어서 저장\n",
        "    chunks = []\n",
        "    for i in range(0, len(audio), chunk_length_samples):\n",
        "        chunk = audio[i:i+chunk_length_samples]\n",
        "        chunk_filename = f'chunk_{i // chunk_length_samples + 1}.wav'\n",
        "        chunk_path = os.path.join(output_dir, chunk_filename)\n",
        "        sf.write(chunk_path, chunk, sr)  # chunk 저장\n",
        "        chunks.append(chunk_path)\n",
        "\n",
        "    return chunks\n",
        "\n",
        "# 메인 실행 부분\n",
        "def main(input_audio_path, output_dir='output_audio', chunk_length_sec=5):\n",
        "    # 오디오 파일 로드\n",
        "    audio, sr = load_audio(input_audio_path)\n",
        "\n",
        "    # 오디오를 청크로 나누고 저장\n",
        "    chunks = split_audio(audio, sr, chunk_length_sec, output_dir)\n",
        "\n",
        "    # 저장된 청크 파일 리스트 출력\n",
        "    print(f'총 {len(chunks)}개의 청크가 {output_dir} 디렉토리에 저장되었습니다.')\n",
        "    return chunks\n",
        "\n",
        "# 사용 예시\n",
        "input_audio_path = '/content/drive/MyDrive/data/chosubin.mp3'  # 원본 음성 파일 경로\n",
        "output_dir = '/content/drive/MyDrive/humanchunk'     # 분할된 파일을 저장할 디렉토리\n",
        "chunks = main(input_audio_path, output_dir, chunk_length_sec=5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LJRu9LxZKluq",
        "outputId": "8247a063-e34f-4791-cc6b-157c076ba778"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "총 202개의 청크가 /content/drive/MyDrive/aichunk 디렉토리에 저장되었습니다.\n"
          ]
        }
      ],
      "source": [
        "import librosa\n",
        "import os\n",
        "import soundfile as sf\n",
        "\n",
        "# 음성 파일을 로드하는 함수\n",
        "def load_audio(file_path, target_sr=16000):\n",
        "    audio, sr = librosa.load(file_path, sr=target_sr)\n",
        "    return audio, sr\n",
        "\n",
        "# 음성을 청크로 나누는 함수\n",
        "def split_audio(audio, sr, chunk_length_sec=5, output_dir='output_audio'):\n",
        "    # chunk 길이를 샘플로 변환 (초 -> 샘플)\n",
        "    chunk_length_samples = chunk_length_sec * sr\n",
        "\n",
        "    # 저장할 디렉토리 생성 (없으면)\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    # 청크로 나누어서 저장\n",
        "    chunks = []\n",
        "    for i in range(0, len(audio), chunk_length_samples):\n",
        "        chunk = audio[i:i+chunk_length_samples]\n",
        "        chunk_filename = f'chunk_{i // chunk_length_samples + 1}.wav'\n",
        "        chunk_path = os.path.join(output_dir, chunk_filename)\n",
        "        sf.write(chunk_path, chunk, sr)  # chunk 저장\n",
        "        chunks.append(chunk_path)\n",
        "\n",
        "    return chunks\n",
        "\n",
        "# 메인 실행 부분\n",
        "def main(input_audio_path, output_dir='output_audio', chunk_length_sec=5):\n",
        "    # 오디오 파일 로드\n",
        "    audio, sr = load_audio(input_audio_path)\n",
        "\n",
        "    # 오디오를 청크로 나누고 저장\n",
        "    chunks = split_audio(audio, sr, chunk_length_sec, output_dir)\n",
        "\n",
        "    # 저장된 청크 파일 리스트 출력\n",
        "    print(f'총 {len(chunks)}개의 청크가 {output_dir} 디렉토리에 저장되었습니다.')\n",
        "    return chunks\n",
        "\n",
        "# 사용 예시\n",
        "input_audio_path = '/content/drive/MyDrive/data/새+프로젝트.mp3'  # 원본 음성 파일 경로\n",
        "output_dir = '/content/drive/MyDrive/aichunk'     # 분할된 파일을 저장할 디렉토리\n",
        "chunks = main(input_audio_path, output_dir, chunk_length_sec=5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1sBnV-f6--qm",
        "outputId": "deba9b1d-d1dc-4bb2-97eb-683b7412ac41"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (128) may be set too high. Or, the value for `n_freqs` (201) may be set too low.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/20], Training Loss: 21.4885\n",
            "Epoch [2/20], Training Loss: 21.6023\n",
            "Epoch [3/20], Training Loss: 22.6085\n",
            "Epoch [4/20], Training Loss: 20.8773\n",
            "Epoch [5/20], Training Loss: 23.6110\n",
            "Epoch [6/20], Training Loss: 21.0165\n",
            "Epoch [7/20], Training Loss: 20.3157\n",
            "Epoch [8/20], Training Loss: 19.5593\n",
            "Epoch [9/20], Training Loss: 20.8824\n",
            "Epoch [10/20], Training Loss: 21.2178\n",
            "Epoch [11/20], Training Loss: 21.6284\n",
            "Epoch [12/20], Training Loss: 21.2100\n",
            "Epoch [13/20], Training Loss: 23.2248\n",
            "Epoch [14/20], Training Loss: 19.8919\n",
            "Epoch [15/20], Training Loss: 19.5243\n",
            "Epoch [16/20], Training Loss: 22.8506\n",
            "Epoch [17/20], Training Loss: 21.6857\n",
            "Epoch [18/20], Training Loss: 20.2907\n",
            "Epoch [19/20], Training Loss: 22.5964\n",
            "Epoch [20/20], Training Loss: 22.7092\n",
            "\n",
            "Human Voice Reconstruction Errors:\n",
            "Human Sample 1: Reconstruction Error = 19.0515\n",
            "Human Sample 2: Reconstruction Error = 16.5600\n",
            "Human Sample 3: Reconstruction Error = 17.5154\n",
            "Human Sample 4: Reconstruction Error = 17.1839\n",
            "Human Sample 5: Reconstruction Error = 16.2322\n",
            "Human Sample 6: Reconstruction Error = 17.7790\n",
            "Human Sample 7: Reconstruction Error = 18.6403\n",
            "Human Sample 8: Reconstruction Error = 23.2286\n",
            "Human Sample 9: Reconstruction Error = 19.7847\n",
            "Human Sample 10: Reconstruction Error = 20.2122\n",
            "Human Sample 11: Reconstruction Error = 20.4166\n",
            "Human Sample 12: Reconstruction Error = 20.6298\n",
            "Human Sample 13: Reconstruction Error = 21.6104\n",
            "Human Sample 14: Reconstruction Error = 20.6521\n",
            "Human Sample 15: Reconstruction Error = 20.5034\n",
            "Human Sample 16: Reconstruction Error = 20.7494\n",
            "Human Sample 17: Reconstruction Error = 20.9947\n",
            "Human Sample 18: Reconstruction Error = 20.7480\n",
            "Human Sample 19: Reconstruction Error = 22.2190\n",
            "Human Sample 20: Reconstruction Error = 22.9403\n",
            "Human Sample 21: Reconstruction Error = 22.6607\n",
            "Human Sample 22: Reconstruction Error = 21.0288\n",
            "Human Sample 23: Reconstruction Error = 21.1215\n",
            "Human Sample 24: Reconstruction Error = 18.1818\n",
            "Human Sample 25: Reconstruction Error = 24.8227\n",
            "Human Sample 26: Reconstruction Error = 20.3768\n",
            "Human Sample 27: Reconstruction Error = 19.2721\n",
            "Human Sample 28: Reconstruction Error = 21.7781\n",
            "Human Sample 29: Reconstruction Error = 22.9217\n",
            "Human Sample 30: Reconstruction Error = 135.0702\n",
            "Human Sample 31: Reconstruction Error = 19.2279\n",
            "Human Sample 32: Reconstruction Error = 21.2287\n",
            "Human Sample 33: Reconstruction Error = 20.1623\n",
            "Human Sample 34: Reconstruction Error = 19.7637\n",
            "Human Sample 35: Reconstruction Error = 21.5314\n",
            "Human Sample 36: Reconstruction Error = 20.9261\n",
            "Human Sample 37: Reconstruction Error = 22.4356\n",
            "Human Sample 38: Reconstruction Error = 20.4890\n",
            "Human Sample 39: Reconstruction Error = 20.3123\n",
            "Human Sample 40: Reconstruction Error = 19.3569\n",
            "Human Sample 41: Reconstruction Error = 23.3491\n",
            "Human Sample 42: Reconstruction Error = 21.3123\n",
            "Human Sample 43: Reconstruction Error = 20.4828\n",
            "Human Sample 44: Reconstruction Error = 18.7551\n",
            "Human Sample 45: Reconstruction Error = 22.7468\n",
            "Human Sample 46: Reconstruction Error = 24.9897\n",
            "Human Sample 47: Reconstruction Error = 19.7625\n",
            "Human Sample 48: Reconstruction Error = 20.4795\n",
            "Human Sample 49: Reconstruction Error = 19.3819\n",
            "Human Sample 50: Reconstruction Error = 19.1664\n",
            "Human Sample 51: Reconstruction Error = 20.4568\n",
            "Human Sample 52: Reconstruction Error = 20.5630\n",
            "Human Sample 53: Reconstruction Error = 21.2877\n",
            "Human Sample 54: Reconstruction Error = 18.9909\n",
            "Human Sample 55: Reconstruction Error = 20.4899\n",
            "Human Sample 56: Reconstruction Error = 21.8489\n",
            "Human Sample 57: Reconstruction Error = 23.9819\n",
            "Human Sample 58: Reconstruction Error = 19.0294\n",
            "Human Sample 59: Reconstruction Error = 25.1149\n",
            "Human Sample 60: Reconstruction Error = 20.9015\n",
            "Human Sample 61: Reconstruction Error = 22.4900\n",
            "Human Sample 62: Reconstruction Error = 19.0963\n",
            "Human Sample 63: Reconstruction Error = 21.6339\n",
            "Human Sample 64: Reconstruction Error = 19.8458\n",
            "Human Sample 65: Reconstruction Error = 20.4446\n",
            "Human Sample 66: Reconstruction Error = 20.6926\n",
            "Human Sample 67: Reconstruction Error = 20.9592\n",
            "Human Sample 68: Reconstruction Error = 22.6695\n",
            "Human Sample 69: Reconstruction Error = 19.8713\n",
            "Human Sample 70: Reconstruction Error = 21.1774\n",
            "Human Sample 71: Reconstruction Error = 22.2451\n",
            "Human Sample 72: Reconstruction Error = 20.3562\n",
            "Human Sample 73: Reconstruction Error = 24.3926\n",
            "Human Sample 74: Reconstruction Error = 24.1650\n",
            "Human Sample 75: Reconstruction Error = 21.9233\n",
            "Human Sample 76: Reconstruction Error = 21.0182\n",
            "Human Sample 77: Reconstruction Error = 19.5059\n",
            "Human Sample 78: Reconstruction Error = 24.6519\n",
            "Human Sample 79: Reconstruction Error = 18.7241\n",
            "Human Sample 80: Reconstruction Error = 23.4876\n",
            "Human Sample 81: Reconstruction Error = 133.1372\n",
            "Human Sample 82: Reconstruction Error = 23.8417\n",
            "Human Sample 83: Reconstruction Error = 20.6341\n",
            "Human Sample 84: Reconstruction Error = 23.7848\n",
            "Human Sample 85: Reconstruction Error = 20.6613\n",
            "Human Sample 86: Reconstruction Error = 21.0794\n",
            "Human Sample 87: Reconstruction Error = 17.4242\n",
            "Human Sample 88: Reconstruction Error = 15.6785\n",
            "Human Sample 89: Reconstruction Error = 15.0478\n",
            "Human Sample 90: Reconstruction Error = 20.5245\n",
            "Human Sample 91: Reconstruction Error = 20.6698\n",
            "Human Sample 92: Reconstruction Error = 26.3432\n",
            "Human Sample 93: Reconstruction Error = 21.9805\n",
            "Human Sample 94: Reconstruction Error = 20.2039\n",
            "Human Sample 95: Reconstruction Error = 21.4654\n",
            "Human Sample 96: Reconstruction Error = 24.1488\n",
            "Human Sample 97: Reconstruction Error = 21.1000\n",
            "Human Sample 98: Reconstruction Error = 23.0553\n",
            "Human Sample 99: Reconstruction Error = 20.1951\n",
            "Human Sample 100: Reconstruction Error = 21.7218\n",
            "Human Sample 101: Reconstruction Error = 20.0145\n",
            "Human Sample 102: Reconstruction Error = 23.5491\n",
            "Human Sample 103: Reconstruction Error = 22.2172\n",
            "Human Sample 104: Reconstruction Error = 21.3143\n",
            "Human Sample 105: Reconstruction Error = 24.8635\n",
            "Human Sample 106: Reconstruction Error = 22.1981\n",
            "Human Sample 107: Reconstruction Error = 19.2363\n",
            "Human Sample 108: Reconstruction Error = 21.0473\n",
            "Human Sample 109: Reconstruction Error = 23.2728\n",
            "Human Sample 110: Reconstruction Error = 23.7382\n",
            "Human Sample 111: Reconstruction Error = 20.7185\n",
            "Human Sample 112: Reconstruction Error = 24.6078\n",
            "Human Sample 113: Reconstruction Error = 21.3784\n",
            "Human Sample 114: Reconstruction Error = 23.8870\n",
            "Human Sample 115: Reconstruction Error = 20.8269\n",
            "Human Sample 116: Reconstruction Error = 24.6619\n",
            "Human Sample 117: Reconstruction Error = 21.3996\n",
            "Human Sample 118: Reconstruction Error = 24.5641\n",
            "Human Sample 119: Reconstruction Error = 109.1422\n",
            "Human Sample 120: Reconstruction Error = 47.0072\n",
            "Human Sample 121: Reconstruction Error = 21.3052\n",
            "Human Sample 122: Reconstruction Error = 22.9720\n",
            "Human Sample 123: Reconstruction Error = 21.7340\n",
            "Human Sample 124: Reconstruction Error = 21.2267\n",
            "Human Sample 125: Reconstruction Error = 24.3034\n",
            "Human Sample 126: Reconstruction Error = 23.2006\n",
            "Human Sample 127: Reconstruction Error = 23.8910\n",
            "Human Sample 128: Reconstruction Error = 23.3514\n",
            "Human Sample 129: Reconstruction Error = 21.4616\n",
            "Human Sample 130: Reconstruction Error = 22.9230\n",
            "Human Sample 131: Reconstruction Error = 22.2597\n",
            "Human Sample 132: Reconstruction Error = 18.7777\n",
            "Human Sample 133: Reconstruction Error = 20.1422\n",
            "Human Sample 134: Reconstruction Error = 22.5320\n",
            "Human Sample 135: Reconstruction Error = 21.6535\n",
            "Human Sample 136: Reconstruction Error = 18.9091\n",
            "Human Sample 137: Reconstruction Error = 21.3610\n",
            "Human Sample 138: Reconstruction Error = 22.8469\n",
            "Human Sample 139: Reconstruction Error = 19.9944\n",
            "Human Sample 140: Reconstruction Error = 20.0123\n",
            "Human Sample 141: Reconstruction Error = 20.1411\n",
            "Human Sample 142: Reconstruction Error = 22.0930\n",
            "Human Sample 143: Reconstruction Error = 20.8123\n",
            "Human Sample 144: Reconstruction Error = 25.9581\n",
            "Human Sample 145: Reconstruction Error = 21.0853\n",
            "Human Sample 146: Reconstruction Error = 19.4705\n",
            "Human Sample 147: Reconstruction Error = 19.7130\n",
            "Human Sample 148: Reconstruction Error = 21.6136\n",
            "Human Sample 149: Reconstruction Error = 20.9036\n",
            "Human Sample 150: Reconstruction Error = 133.9969\n",
            "Human Sample 151: Reconstruction Error = 20.6208\n",
            "Human Sample 152: Reconstruction Error = 20.7194\n",
            "Human Sample 153: Reconstruction Error = 21.4352\n",
            "Human Sample 154: Reconstruction Error = 20.5037\n",
            "Human Sample 155: Reconstruction Error = 22.8776\n",
            "Human Sample 156: Reconstruction Error = 20.8290\n",
            "Human Sample 157: Reconstruction Error = 21.7209\n",
            "Human Sample 158: Reconstruction Error = 20.7444\n",
            "Human Sample 159: Reconstruction Error = 24.9838\n",
            "Human Sample 160: Reconstruction Error = 20.3540\n",
            "Human Sample 161: Reconstruction Error = 21.0642\n",
            "Human Sample 162: Reconstruction Error = 20.6204\n",
            "Human Sample 163: Reconstruction Error = 23.3319\n",
            "Human Sample 164: Reconstruction Error = 23.2559\n",
            "Human Sample 165: Reconstruction Error = 21.9875\n",
            "Human Sample 166: Reconstruction Error = 23.7487\n",
            "Human Sample 167: Reconstruction Error = 22.5808\n",
            "Human Sample 168: Reconstruction Error = 23.5157\n",
            "Human Sample 169: Reconstruction Error = 20.2693\n",
            "Human Sample 170: Reconstruction Error = 20.5696\n",
            "Human Sample 171: Reconstruction Error = 22.1021\n",
            "Human Sample 172: Reconstruction Error = 18.7726\n",
            "Human Sample 173: Reconstruction Error = 19.0138\n",
            "Human Sample 174: Reconstruction Error = 18.3551\n",
            "Human Sample 175: Reconstruction Error = 21.2880\n",
            "Human Sample 176: Reconstruction Error = 21.2164\n",
            "Human Sample 177: Reconstruction Error = 22.3228\n",
            "Human Sample 178: Reconstruction Error = 22.3655\n",
            "Human Sample 179: Reconstruction Error = 21.8892\n",
            "Human Sample 180: Reconstruction Error = 21.6166\n",
            "Human Sample 181: Reconstruction Error = 26.1600\n",
            "Human Sample 182: Reconstruction Error = 70.1229\n",
            "Human Sample 183: Reconstruction Error = 19.9064\n",
            "Human Sample 184: Reconstruction Error = 22.5872\n",
            "Human Sample 185: Reconstruction Error = 23.4278\n",
            "Human Sample 186: Reconstruction Error = 18.9564\n",
            "Human Sample 187: Reconstruction Error = 20.0991\n",
            "Human Sample 188: Reconstruction Error = 20.0623\n",
            "Human Sample 189: Reconstruction Error = 19.7056\n",
            "Human Sample 190: Reconstruction Error = 20.3618\n",
            "Human Sample 191: Reconstruction Error = 24.1310\n",
            "Human Sample 192: Reconstruction Error = 19.5391\n",
            "Human Sample 193: Reconstruction Error = 21.3041\n",
            "Human Sample 194: Reconstruction Error = 19.6227\n",
            "Human Sample 195: Reconstruction Error = 21.8016\n",
            "Human Sample 196: Reconstruction Error = 20.0987\n",
            "Human Sample 197: Reconstruction Error = 22.5870\n",
            "Human Sample 198: Reconstruction Error = 19.8149\n",
            "Human Sample 199: Reconstruction Error = 22.1712\n",
            "Human Sample 200: Reconstruction Error = 20.1570\n",
            "Human Sample 201: Reconstruction Error = 19.9733\n",
            "Human Sample 202: Reconstruction Error = 19.7830\n",
            "Human Sample 203: Reconstruction Error = 12.8611\n",
            "23.673190154465548\n",
            "\n",
            "AI Voice Reconstruction Errors:\n",
            "AI Sample 1: Reconstruction Error = 48.8304\n",
            "AI Sample 2: Reconstruction Error = 49.6078\n",
            "AI Sample 3: Reconstruction Error = 35.3232\n",
            "AI Sample 4: Reconstruction Error = 49.6139\n",
            "AI Sample 5: Reconstruction Error = 46.8396\n",
            "AI Sample 6: Reconstruction Error = 49.1469\n",
            "AI Sample 7: Reconstruction Error = 39.5013\n",
            "AI Sample 8: Reconstruction Error = 65.1515\n",
            "AI Sample 9: Reconstruction Error = 39.0975\n",
            "AI Sample 10: Reconstruction Error = 30.3441\n",
            "AI Sample 11: Reconstruction Error = 63.3934\n",
            "AI Sample 12: Reconstruction Error = 44.4172\n",
            "AI Sample 13: Reconstruction Error = 64.5923\n",
            "AI Sample 14: Reconstruction Error = 46.1854\n",
            "AI Sample 15: Reconstruction Error = 47.9036\n",
            "AI Sample 16: Reconstruction Error = 55.9356\n",
            "AI Sample 17: Reconstruction Error = 49.9507\n",
            "AI Sample 18: Reconstruction Error = 48.4457\n",
            "AI Sample 19: Reconstruction Error = 68.1029\n",
            "AI Sample 20: Reconstruction Error = 22.3623\n",
            "AI Sample 21: Reconstruction Error = 63.0842\n",
            "AI Sample 22: Reconstruction Error = 55.8476\n",
            "AI Sample 23: Reconstruction Error = 74.6126\n",
            "AI Sample 24: Reconstruction Error = 48.7507\n",
            "AI Sample 25: Reconstruction Error = 34.7872\n",
            "AI Sample 26: Reconstruction Error = 50.8944\n",
            "AI Sample 27: Reconstruction Error = 50.1690\n",
            "AI Sample 28: Reconstruction Error = 51.7396\n",
            "AI Sample 29: Reconstruction Error = 33.8370\n",
            "AI Sample 30: Reconstruction Error = 56.4878\n",
            "AI Sample 31: Reconstruction Error = 53.9921\n",
            "AI Sample 32: Reconstruction Error = 66.9558\n",
            "AI Sample 33: Reconstruction Error = 69.6472\n",
            "AI Sample 34: Reconstruction Error = 50.6062\n",
            "AI Sample 35: Reconstruction Error = 59.8063\n",
            "AI Sample 36: Reconstruction Error = 46.4089\n",
            "AI Sample 37: Reconstruction Error = 78.4386\n",
            "AI Sample 38: Reconstruction Error = 34.6287\n",
            "AI Sample 39: Reconstruction Error = 58.8639\n",
            "AI Sample 40: Reconstruction Error = 49.2659\n",
            "AI Sample 41: Reconstruction Error = 45.7804\n",
            "AI Sample 42: Reconstruction Error = 34.0114\n",
            "AI Sample 43: Reconstruction Error = 53.0596\n",
            "AI Sample 44: Reconstruction Error = 35.2498\n",
            "AI Sample 45: Reconstruction Error = 59.7851\n",
            "AI Sample 46: Reconstruction Error = 60.0519\n",
            "AI Sample 47: Reconstruction Error = 53.2587\n",
            "AI Sample 48: Reconstruction Error = 50.9495\n",
            "AI Sample 49: Reconstruction Error = 59.1314\n",
            "AI Sample 50: Reconstruction Error = 40.4461\n",
            "AI Sample 51: Reconstruction Error = 61.9741\n",
            "AI Sample 52: Reconstruction Error = 61.3669\n",
            "AI Sample 53: Reconstruction Error = 36.8522\n",
            "AI Sample 54: Reconstruction Error = 37.0614\n",
            "AI Sample 55: Reconstruction Error = 59.1995\n",
            "AI Sample 56: Reconstruction Error = 39.2049\n",
            "AI Sample 57: Reconstruction Error = 59.8362\n",
            "AI Sample 58: Reconstruction Error = 35.8359\n",
            "AI Sample 59: Reconstruction Error = 61.7676\n",
            "AI Sample 60: Reconstruction Error = 42.3939\n",
            "AI Sample 61: Reconstruction Error = 47.2678\n",
            "AI Sample 62: Reconstruction Error = 52.1133\n",
            "AI Sample 63: Reconstruction Error = 54.2153\n",
            "AI Sample 64: Reconstruction Error = 74.0660\n",
            "AI Sample 65: Reconstruction Error = 29.0751\n",
            "AI Sample 66: Reconstruction Error = 62.5106\n",
            "AI Sample 67: Reconstruction Error = 34.1922\n",
            "AI Sample 68: Reconstruction Error = 52.7368\n",
            "AI Sample 69: Reconstruction Error = 30.3440\n",
            "AI Sample 70: Reconstruction Error = 61.2574\n",
            "AI Sample 71: Reconstruction Error = 49.2693\n",
            "AI Sample 72: Reconstruction Error = 32.4647\n",
            "AI Sample 73: Reconstruction Error = 56.7565\n",
            "AI Sample 74: Reconstruction Error = 23.9885\n",
            "AI Sample 75: Reconstruction Error = 54.3812\n",
            "AI Sample 76: Reconstruction Error = 63.2232\n",
            "AI Sample 77: Reconstruction Error = 60.8286\n",
            "AI Sample 78: Reconstruction Error = 55.9078\n",
            "AI Sample 79: Reconstruction Error = 32.3124\n",
            "AI Sample 80: Reconstruction Error = 60.2675\n",
            "AI Sample 81: Reconstruction Error = 86.6956\n",
            "AI Sample 82: Reconstruction Error = 40.9771\n",
            "AI Sample 83: Reconstruction Error = 19.6077\n",
            "AI Sample 84: Reconstruction Error = 96.0050\n",
            "AI Sample 85: Reconstruction Error = 64.4231\n",
            "AI Sample 86: Reconstruction Error = 30.0856\n",
            "AI Sample 87: Reconstruction Error = 89.2331\n",
            "AI Sample 88: Reconstruction Error = 50.2308\n",
            "AI Sample 89: Reconstruction Error = 50.4472\n",
            "AI Sample 90: Reconstruction Error = 58.7624\n",
            "AI Sample 91: Reconstruction Error = 37.5993\n",
            "AI Sample 92: Reconstruction Error = 41.4566\n",
            "AI Sample 93: Reconstruction Error = 65.3823\n",
            "AI Sample 94: Reconstruction Error = 75.0443\n",
            "AI Sample 95: Reconstruction Error = 36.0089\n",
            "AI Sample 96: Reconstruction Error = 41.2470\n",
            "AI Sample 97: Reconstruction Error = 51.2020\n",
            "AI Sample 98: Reconstruction Error = 78.1078\n",
            "AI Sample 99: Reconstruction Error = 72.0244\n",
            "AI Sample 100: Reconstruction Error = 64.2831\n",
            "AI Sample 101: Reconstruction Error = 74.6125\n",
            "AI Sample 102: Reconstruction Error = 66.6509\n",
            "AI Sample 103: Reconstruction Error = 48.3508\n",
            "AI Sample 104: Reconstruction Error = 79.0500\n",
            "AI Sample 105: Reconstruction Error = 30.5983\n",
            "AI Sample 106: Reconstruction Error = 80.2186\n",
            "AI Sample 107: Reconstruction Error = 74.7507\n",
            "AI Sample 108: Reconstruction Error = 58.4318\n",
            "AI Sample 109: Reconstruction Error = 42.1444\n",
            "AI Sample 110: Reconstruction Error = 58.7919\n",
            "AI Sample 111: Reconstruction Error = 35.1258\n",
            "AI Sample 112: Reconstruction Error = 56.3921\n",
            "AI Sample 113: Reconstruction Error = 75.9701\n",
            "AI Sample 114: Reconstruction Error = 40.9564\n",
            "AI Sample 115: Reconstruction Error = 45.0791\n",
            "AI Sample 116: Reconstruction Error = 85.1114\n",
            "AI Sample 117: Reconstruction Error = 66.1625\n",
            "AI Sample 118: Reconstruction Error = 51.2023\n",
            "AI Sample 119: Reconstruction Error = 37.9028\n",
            "AI Sample 120: Reconstruction Error = 66.0095\n",
            "AI Sample 121: Reconstruction Error = 56.3796\n",
            "AI Sample 122: Reconstruction Error = 52.7424\n",
            "AI Sample 123: Reconstruction Error = 50.3787\n",
            "AI Sample 124: Reconstruction Error = 45.5106\n",
            "AI Sample 125: Reconstruction Error = 54.0197\n",
            "AI Sample 126: Reconstruction Error = 47.0859\n",
            "AI Sample 127: Reconstruction Error = 59.9571\n",
            "AI Sample 128: Reconstruction Error = 65.1423\n",
            "AI Sample 129: Reconstruction Error = 47.2455\n",
            "AI Sample 130: Reconstruction Error = 62.6567\n",
            "AI Sample 131: Reconstruction Error = 70.2240\n",
            "AI Sample 132: Reconstruction Error = 41.5050\n",
            "AI Sample 133: Reconstruction Error = 59.4049\n",
            "AI Sample 134: Reconstruction Error = 58.1463\n",
            "AI Sample 135: Reconstruction Error = 58.9532\n",
            "AI Sample 136: Reconstruction Error = 87.7977\n",
            "AI Sample 137: Reconstruction Error = 78.3849\n",
            "AI Sample 138: Reconstruction Error = 54.4017\n",
            "AI Sample 139: Reconstruction Error = 36.3593\n",
            "AI Sample 140: Reconstruction Error = 54.4661\n",
            "AI Sample 141: Reconstruction Error = 75.8791\n",
            "AI Sample 142: Reconstruction Error = 61.4490\n",
            "AI Sample 143: Reconstruction Error = 22.6094\n",
            "AI Sample 144: Reconstruction Error = 61.0046\n",
            "AI Sample 145: Reconstruction Error = 58.0901\n",
            "AI Sample 146: Reconstruction Error = 30.9004\n",
            "AI Sample 147: Reconstruction Error = 50.5126\n",
            "AI Sample 148: Reconstruction Error = 71.7579\n",
            "AI Sample 149: Reconstruction Error = 32.1240\n",
            "AI Sample 150: Reconstruction Error = 59.2044\n",
            "AI Sample 151: Reconstruction Error = 76.3502\n",
            "AI Sample 152: Reconstruction Error = 53.8038\n",
            "AI Sample 153: Reconstruction Error = 61.6553\n",
            "AI Sample 154: Reconstruction Error = 48.8789\n",
            "AI Sample 155: Reconstruction Error = 63.5090\n",
            "AI Sample 156: Reconstruction Error = 57.6182\n",
            "AI Sample 157: Reconstruction Error = 43.5346\n",
            "AI Sample 158: Reconstruction Error = 50.1171\n",
            "AI Sample 159: Reconstruction Error = 46.0907\n",
            "AI Sample 160: Reconstruction Error = 57.3876\n",
            "AI Sample 161: Reconstruction Error = 52.4509\n",
            "AI Sample 162: Reconstruction Error = 32.6424\n",
            "AI Sample 163: Reconstruction Error = 37.1378\n",
            "AI Sample 164: Reconstruction Error = 61.9862\n",
            "AI Sample 165: Reconstruction Error = 47.5425\n",
            "AI Sample 166: Reconstruction Error = 64.1096\n",
            "AI Sample 167: Reconstruction Error = 80.9436\n",
            "AI Sample 168: Reconstruction Error = 48.2110\n",
            "AI Sample 169: Reconstruction Error = 47.9530\n",
            "AI Sample 170: Reconstruction Error = 60.3828\n",
            "AI Sample 171: Reconstruction Error = 112.5139\n",
            "AI Sample 172: Reconstruction Error = nan\n",
            "AI Sample 173: Reconstruction Error = nan\n",
            "AI Sample 174: Reconstruction Error = 243.5823\n",
            "AI Sample 175: Reconstruction Error = 37.5867\n",
            "AI Sample 176: Reconstruction Error = 59.8305\n",
            "AI Sample 177: Reconstruction Error = 66.1169\n",
            "AI Sample 178: Reconstruction Error = 42.2723\n",
            "AI Sample 179: Reconstruction Error = 24.2559\n",
            "AI Sample 180: Reconstruction Error = 60.9487\n",
            "AI Sample 181: Reconstruction Error = 49.6375\n",
            "AI Sample 182: Reconstruction Error = 46.4027\n",
            "AI Sample 183: Reconstruction Error = 50.4929\n",
            "AI Sample 184: Reconstruction Error = 74.4384\n",
            "AI Sample 185: Reconstruction Error = 55.3565\n",
            "AI Sample 186: Reconstruction Error = 59.2460\n",
            "AI Sample 187: Reconstruction Error = 51.4405\n",
            "AI Sample 188: Reconstruction Error = 33.3411\n",
            "AI Sample 189: Reconstruction Error = 64.5396\n",
            "AI Sample 190: Reconstruction Error = 55.6253\n",
            "AI Sample 191: Reconstruction Error = 36.5430\n",
            "AI Sample 192: Reconstruction Error = 35.8772\n",
            "AI Sample 193: Reconstruction Error = 37.0184\n",
            "AI Sample 194: Reconstruction Error = 63.3099\n",
            "AI Sample 195: Reconstruction Error = 54.9790\n",
            "AI Sample 196: Reconstruction Error = 48.2898\n",
            "AI Sample 197: Reconstruction Error = 71.5859\n",
            "AI Sample 198: Reconstruction Error = 28.9444\n",
            "AI Sample 199: Reconstruction Error = 57.5163\n",
            "AI Sample 200: Reconstruction Error = 52.4732\n",
            "AI Sample 201: Reconstruction Error = 62.7868\n",
            "AI Sample 202: Reconstruction Error = 45.7975\n",
            "53.909139623736394\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import torchaudio\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import torchaudio.transforms as T\n",
        "\n",
        "# 오토인코더 모델 정의\n",
        "class ConvAutoencoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ConvAutoencoder, self).__init__()\n",
        "\n",
        "        # Encoder\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(1, 16, 3, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(16, 32, 3, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, 3, stride=2, padding=1),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        # Decoder\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.ConvTranspose2d(64, 32, 3, stride=2, padding=1, output_padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(32, 16, 3, stride=2, padding=1, output_padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(16, 1, 3, stride=2, padding=1, output_padding=1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        encoded = self.encoder(x)\n",
        "        decoded = self.decoder(encoded)\n",
        "        return decoded\n",
        "\n",
        "# 음성 파일을 Mel-spectrogram으로 변환하는 함수\n",
        "def audio_to_mel_spectrogram(waveform, sample_rate=16000, target_length=16000):\n",
        "    # Mel-spectrogram 변환\n",
        "    mel_spec = T.MelSpectrogram(sample_rate=sample_rate)(waveform)  # Mel-Spectrogram 생성\n",
        "    mel_spec_db = T.AmplitudeToDB()(mel_spec)  # 로그 스펙트로그램으로 변환\n",
        "\n",
        "    # 패딩 또는 자르기 (길이를 target_length로 맞추기)\n",
        "    num_samples = mel_spec_db.shape[-1]\n",
        "\n",
        "    if num_samples < target_length:\n",
        "        # 패딩: 짧은 음성 데이터를 0으로 채워서 길이를 맞춤\n",
        "        padding = target_length - num_samples\n",
        "        mel_spec_db = torch.cat([mel_spec_db, torch.zeros(1, mel_spec_db.shape[1], padding)], dim=-1)\n",
        "    elif num_samples > target_length:\n",
        "        # 자르기: 긴 음성 데이터를 target_length로 잘라냄\n",
        "        mel_spec_db = mel_spec_db[:, :, :target_length]\n",
        "\n",
        "    return mel_spec_db\n",
        "\n",
        "# 음성 파일 로드 및 전처리 함수\n",
        "def load_audio_file(file_path, sample_rate=16000, target_length=16000):\n",
        "    waveform, original_sample_rate = torchaudio.load(file_path)\n",
        "\n",
        "    # 샘플링 레이트가 다르면 변환\n",
        "    if original_sample_rate != sample_rate:\n",
        "        waveform = torchaudio.transforms.Resample(orig_freq=original_sample_rate, new_freq=sample_rate)(waveform)\n",
        "\n",
        "    # 정규화: 음성 데이터를 [-1, 1] 범위로 정규화\n",
        "    waveform = waveform / waveform.abs().max()\n",
        "\n",
        "    # Mel-spectrogram으로 변환 및 길이 맞추기\n",
        "    mel_spectrogram = audio_to_mel_spectrogram(waveform, sample_rate, target_length)\n",
        "\n",
        "    return mel_spectrogram\n",
        "\n",
        "# 데이터셋 로드 함수\n",
        "def load_dataset(file_paths, sample_rate=16000, target_length=16000):\n",
        "    spectrograms = []\n",
        "    for file_path in file_paths:\n",
        "        mel_spectrogram = load_audio_file(file_path, sample_rate, target_length)\n",
        "        spectrograms.append(mel_spectrogram)\n",
        "    return torch.stack(spectrograms)  # [N, 1, H, W] 형식으로 반환\n",
        "\n",
        "# 데이터 로딩\n",
        "human_data_dir = '/content/drive/MyDrive/humanchunk'\n",
        "human_files = [os.path.join(human_data_dir, f) for f in os.listdir(human_data_dir) if f.endswith('.wav')]\n",
        "human_spectrograms = load_dataset(human_files)\n",
        "\n",
        "ai_data_dir = '/content/drive/MyDrive/aichunk'\n",
        "ai_files = [os.path.join(ai_data_dir, f) for f in os.listdir(ai_data_dir) if f.endswith('.wav')]\n",
        "ai_spectrograms = load_dataset(ai_files)\n",
        "\n",
        "# DataLoader 설정\n",
        "batch_size = 8\n",
        "human_dataset = TensorDataset(human_spectrograms)\n",
        "dataloader = DataLoader(human_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# 모델 및 손실 함수, 옵티마이저 설정\n",
        "model = ConvAutoencoder()\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# 모델 학습\n",
        "epochs = 20\n",
        "for epoch in range(epochs):\n",
        "    for batch in dataloader:\n",
        "        input_spectrograms = batch[0]\n",
        "\n",
        "        # 모델 예측 및 손실 계산\n",
        "        decoded = model(input_spectrograms)\n",
        "        loss = criterion(decoded, input_spectrograms)\n",
        "\n",
        "        # 역전파 및 최적화\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/{epochs}], Training Loss: {loss.item():.4f}')\n",
        "\n",
        "# 재구성 오차 계산 함수\n",
        "def calculate_reconstruction_error(spectrogram):\n",
        "    with torch.no_grad():\n",
        "        decoded = model(spectrogram.unsqueeze(0))  # [1, 1, H, W] 형식으로 입력\n",
        "        error = criterion(decoded, spectrogram.unsqueeze(0)).item()\n",
        "    return error\n",
        "\n",
        "# 인간 음성의 개별 재구성 오차 출력\n",
        "print(\"\\nHuman Voice Reconstruction Errors:\")\n",
        "humansum=0\n",
        "cnth=0\n",
        "for i, human_spectrogram in enumerate(human_spectrograms):\n",
        "    error = calculate_reconstruction_error(human_spectrogram)\n",
        "    print(f\"Human Sample {i+1}: Reconstruction Error = {error:.4f}\")\n",
        "    if error>=0:\n",
        "      humansum+=error\n",
        "      cnth=i+1\n",
        "print(humansum/cnth)\n",
        "\n",
        "# AI 음성의 개별 재구성 오차 출력\n",
        "print(\"\\nAI Voice Reconstruction Errors:\")\n",
        "aisum=0\n",
        "cnta=0\n",
        "for i, ai_spectrogram in enumerate(ai_spectrograms):\n",
        "    error = calculate_reconstruction_error(ai_spectrogram)\n",
        "    print(f\"AI Sample {i+1}: Reconstruction Error = {error:.4f}\")\n",
        "    if error>=0:\n",
        "      aisum+=error\n",
        "      cnta=i+1\n",
        "print(aisum/cnta)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pP8NKTq4fGlk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 학습 완료 후\n",
        "model_save_path = \"/content/drive/MyDrive/autoencoder/autoencoder_model.pth\"\n",
        "torch.save(model.state_dict(), model_save_path)\n",
        "print(f\"Model saved to {model_save_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "id": "gBHi9nTxWm2M",
        "outputId": "5f0f2b81-2647-4f07-8f87-9e4ff3be1cff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-182bb0f95fac>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 모델 학습 완료 후\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel_save_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/drive/MyDrive/autoencoder/autoencoder_model.pth\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_save_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Model saved to {model_save_path}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "import os\n",
        "import soundfile as sf\n",
        "\n",
        "# 음성 파일을 로드하는 함수\n",
        "def load_audio(file_path, target_sr=16000):\n",
        "    audio, sr = librosa.load(file_path, sr=target_sr)\n",
        "    return audio, sr\n",
        "\n",
        "# 음성을 청크로 나누는 함수\n",
        "def split_audio(audio, sr, chunk_length_sec=5, output_dir='output_audio'):\n",
        "    # chunk 길이를 샘플로 변환 (초 -> 샘플)\n",
        "    chunk_length_samples = chunk_length_sec * sr\n",
        "\n",
        "    # 저장할 디렉토리 생성 (없으면)\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    # 청크로 나누어서 저장\n",
        "    chunks = []\n",
        "    for i in range(0, len(audio), chunk_length_samples):\n",
        "        chunk = audio[i:i+chunk_length_samples]\n",
        "        chunk_filename = f'chunk_{i // chunk_length_samples + 1}.wav'\n",
        "        chunk_path = os.path.join(output_dir, chunk_filename)\n",
        "        sf.write(chunk_path, chunk, sr)  # chunk 저장\n",
        "        chunks.append(chunk_path)\n",
        "\n",
        "    return chunks\n",
        "\n",
        "# 메인 실행 부분\n",
        "def main(input_audio_path, output_dir='output_audio', chunk_length_sec=5):\n",
        "    # 오디오 파일 로드\n",
        "    audio, sr = load_audio(input_audio_path)\n",
        "\n",
        "    # 오디오를 청크로 나누고 저장\n",
        "    chunks = split_audio(audio, sr, chunk_length_sec, output_dir)\n",
        "\n",
        "    # 저장된 청크 파일 리스트 출력\n",
        "    print(f'총 {len(chunks)}개의 청크가 {output_dir} 디렉토리에 저장되었습니다.')\n",
        "    return chunks\n",
        "\n",
        "# 사용 예시\n",
        "input_audio_path = '/content/drive/MyDrive/data/새+프로젝트 (2).mp3'  # 원본 음성 파일 경로\n",
        "output_dir = '/content/drive/MyDrive/data/ai'     # 분할된 파일을 저장할 디렉토리\n",
        "chunks = main(input_audio_path, output_dir, chunk_length_sec=2)\n"
      ],
      "metadata": {
        "id": "ASezs47FS-mB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27360989-ba01-4ca8-ab72-aa2a9fce48fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "총 129개의 청크가 /content/drive/MyDrive/data/ai 디렉토리에 저장되었습니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torchaudio\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import torchaudio.transforms as T\n",
        "\n",
        "# 오토인코더 모델 정의\n",
        "class ConvAutoencoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ConvAutoencoder, self).__init__()\n",
        "\n",
        "        # Encoder\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(1, 16, 3, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(16, 32, 3, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, 3, stride=2, padding=1),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        # Decoder\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.ConvTranspose2d(64, 32, 3, stride=2, padding=1, output_padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(32, 16, 3, stride=2, padding=1, output_padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(16, 1, 3, stride=2, padding=1, output_padding=1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        encoded = self.encoder(x)\n",
        "        decoded = self.decoder(encoded)\n",
        "        return decoded\n",
        "\n",
        "# 음성 파일을 Mel-spectrogram으로 변환하는 함수\n",
        "def audio_to_mel_spectrogram(waveform, sample_rate=16000, target_length=16000):\n",
        "    # Mel-spectrogram 변환\n",
        "    mel_spec = T.MelSpectrogram(sample_rate=sample_rate)(waveform)  # Mel-Spectrogram 생성\n",
        "    mel_spec_db = T.AmplitudeToDB()(mel_spec)  # 로그 스펙트로그램으로 변환\n",
        "\n",
        "    # 패딩 또는 자르기 (길이를 target_length로 맞추기)\n",
        "    num_samples = mel_spec_db.shape[-1]\n",
        "\n",
        "    if num_samples < target_length:\n",
        "        # 패딩: 짧은 음성 데이터를 0으로 채워서 길이를 맞춤\n",
        "        padding = target_length - num_samples\n",
        "        mel_spec_db = torch.cat([mel_spec_db, torch.zeros(1, mel_spec_db.shape[1], padding)], dim=-1)\n",
        "    elif num_samples > target_length:\n",
        "        # 자르기: 긴 음성 데이터를 target_length로 잘라냄\n",
        "        mel_spec_db = mel_spec_db[:, :, :target_length]\n",
        "\n",
        "    return mel_spec_db\n",
        "\n",
        "# 음성 파일 로드 및 전처리 함수\n",
        "def load_audio_file(file_path, sample_rate=16000, target_length=16000):\n",
        "    waveform, original_sample_rate = torchaudio.load(file_path)\n",
        "\n",
        "    # 샘플링 레이트가 다르면 변환\n",
        "    if original_sample_rate != sample_rate:\n",
        "        waveform = torchaudio.transforms.Resample(orig_freq=original_sample_rate, new_freq=sample_rate)(waveform)\n",
        "\n",
        "    # 정규화: 음성 데이터를 [-1, 1] 범위로 정규화\n",
        "    waveform = waveform / waveform.abs().max()\n",
        "\n",
        "    # Mel-spectrogram으로 변환 및 길이 맞추기\n",
        "    mel_spectrogram = audio_to_mel_spectrogram(waveform, sample_rate, target_length)\n",
        "\n",
        "    return mel_spectrogram\n",
        "\n",
        "# 데이터셋 로드 함수\n",
        "def load_dataset(file_paths, sample_rate=16000, target_length=16000):\n",
        "    spectrograms = []\n",
        "    for file_path in file_paths:\n",
        "        mel_spectrogram = load_audio_file(file_path, sample_rate, target_length)\n",
        "        spectrograms.append(mel_spectrogram)\n",
        "    return torch.stack(spectrograms)  # [N, 1, H, W] 형식으로 반환\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "# 재구성 오차 계산 함수\n",
        "def calculate_reconstruction_error(spectrogram):\n",
        "    with torch.no_grad():\n",
        "        decoded = model(spectrogram.unsqueeze(0))  # [1, 1, H, W] 형식으로 입력\n",
        "        error = criterion(decoded, spectrogram.unsqueeze(0)).item()\n",
        "    return error\n",
        "\n",
        "# 모델 로드\n",
        "model_save_path = \"/content/drive/MyDrive/autoencoder/autoencoder_model.pth\"\n",
        "model = ConvAutoencoder()\n",
        "model.load_state_dict(torch.load(model_save_path))\n",
        "model.eval()\n",
        "\n",
        "# 데이터 로딩\n",
        "new_data_dir = '/content/drive/MyDrive/data/ai'\n",
        "new_files = [os.path.join(new_data_dir, f) for f in os.listdir(new_data_dir) if f.endswith('.wav')]\n",
        "new_spectrograms = load_dataset(new_files)\n",
        "\n",
        "# 새 음성의 개별 재구성 오차 출력\n",
        "print(\"\\nNew Voice Reconstruction Errors:\")\n",
        "nsum=0\n",
        "cntn=0\n",
        "for i, new_spectrogram in enumerate(new_spectrograms):\n",
        "    error = calculate_reconstruction_error(new_spectrogram)\n",
        "    print(f\"New Sample {i+1}: Reconstruction Error = {error:.4f}\")\n",
        "    if error>=0:\n",
        "      nsum+=error\n",
        "      cntn=i+1\n",
        "print(nsum/cntn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ivlJfAA-WvXC",
        "outputId": "a6324504-1a7d-43e5-8cff-e01867c2b472"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (128) may be set too high. Or, the value for `n_freqs` (201) may be set too low.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "New Voice Reconstruction Errors:\n",
            "New Sample 1: Reconstruction Error = 49.7207\n",
            "New Sample 2: Reconstruction Error = 20.9204\n",
            "New Sample 3: Reconstruction Error = 20.0723\n",
            "New Sample 4: Reconstruction Error = 44.3286\n",
            "New Sample 5: Reconstruction Error = 11.9431\n",
            "New Sample 6: Reconstruction Error = 19.0803\n",
            "New Sample 7: Reconstruction Error = 19.4096\n",
            "New Sample 8: Reconstruction Error = 23.9484\n",
            "New Sample 9: Reconstruction Error = 43.2083\n",
            "New Sample 10: Reconstruction Error = 16.8326\n",
            "New Sample 11: Reconstruction Error = 17.1320\n",
            "New Sample 12: Reconstruction Error = 39.1951\n",
            "New Sample 13: Reconstruction Error = 34.1409\n",
            "New Sample 14: Reconstruction Error = 31.7406\n",
            "New Sample 15: Reconstruction Error = 35.3160\n",
            "New Sample 16: Reconstruction Error = 28.5766\n",
            "New Sample 17: Reconstruction Error = 22.6037\n",
            "New Sample 18: Reconstruction Error = 16.3649\n",
            "New Sample 19: Reconstruction Error = 52.9520\n",
            "New Sample 20: Reconstruction Error = 36.7415\n",
            "New Sample 21: Reconstruction Error = 62.0864\n",
            "New Sample 22: Reconstruction Error = 33.9922\n",
            "New Sample 23: Reconstruction Error = 15.7844\n",
            "New Sample 24: Reconstruction Error = 32.3434\n",
            "New Sample 25: Reconstruction Error = 42.0545\n",
            "New Sample 26: Reconstruction Error = 33.6208\n",
            "New Sample 27: Reconstruction Error = 18.3766\n",
            "New Sample 28: Reconstruction Error = 18.9412\n",
            "New Sample 29: Reconstruction Error = 48.6837\n",
            "New Sample 30: Reconstruction Error = 32.1632\n",
            "New Sample 31: Reconstruction Error = 34.9016\n",
            "New Sample 32: Reconstruction Error = 18.8830\n",
            "New Sample 33: Reconstruction Error = 17.7999\n",
            "New Sample 34: Reconstruction Error = 56.5262\n",
            "New Sample 35: Reconstruction Error = 42.7781\n",
            "New Sample 36: Reconstruction Error = 19.3432\n",
            "New Sample 37: Reconstruction Error = 34.0430\n",
            "New Sample 38: Reconstruction Error = 10.0652\n",
            "New Sample 39: Reconstruction Error = 56.8750\n",
            "New Sample 40: Reconstruction Error = 15.4557\n",
            "New Sample 41: Reconstruction Error = 37.8693\n",
            "New Sample 42: Reconstruction Error = 43.2570\n",
            "New Sample 43: Reconstruction Error = 12.7722\n",
            "New Sample 44: Reconstruction Error = 44.0740\n",
            "New Sample 45: Reconstruction Error = 12.8359\n",
            "New Sample 46: Reconstruction Error = 35.5107\n",
            "New Sample 47: Reconstruction Error = 39.4238\n",
            "New Sample 48: Reconstruction Error = 31.9999\n",
            "New Sample 49: Reconstruction Error = 45.0157\n",
            "New Sample 50: Reconstruction Error = 31.3159\n",
            "New Sample 51: Reconstruction Error = 39.1259\n",
            "New Sample 52: Reconstruction Error = 17.2656\n",
            "New Sample 53: Reconstruction Error = 32.6641\n",
            "New Sample 54: Reconstruction Error = 34.2533\n",
            "New Sample 55: Reconstruction Error = 40.3260\n",
            "New Sample 56: Reconstruction Error = 39.7378\n",
            "New Sample 57: Reconstruction Error = 22.9147\n",
            "New Sample 58: Reconstruction Error = 44.2043\n",
            "New Sample 59: Reconstruction Error = 30.5091\n",
            "New Sample 60: Reconstruction Error = 17.6662\n",
            "New Sample 61: Reconstruction Error = 54.3596\n",
            "New Sample 62: Reconstruction Error = 15.4581\n",
            "New Sample 63: Reconstruction Error = 40.5365\n",
            "New Sample 64: Reconstruction Error = 43.8530\n",
            "New Sample 65: Reconstruction Error = 44.2267\n",
            "New Sample 66: Reconstruction Error = 32.3869\n",
            "New Sample 67: Reconstruction Error = 28.7672\n",
            "New Sample 68: Reconstruction Error = 37.6473\n",
            "New Sample 69: Reconstruction Error = 10.5399\n",
            "New Sample 70: Reconstruction Error = 40.5988\n",
            "New Sample 71: Reconstruction Error = 34.5097\n",
            "New Sample 72: Reconstruction Error = 37.7766\n",
            "New Sample 73: Reconstruction Error = 41.7306\n",
            "New Sample 74: Reconstruction Error = 29.4166\n",
            "New Sample 75: Reconstruction Error = 23.9988\n",
            "New Sample 76: Reconstruction Error = 32.5991\n",
            "New Sample 77: Reconstruction Error = 36.6917\n",
            "New Sample 78: Reconstruction Error = 35.7710\n",
            "New Sample 79: Reconstruction Error = 32.5909\n",
            "New Sample 80: Reconstruction Error = 23.1165\n",
            "New Sample 81: Reconstruction Error = 39.2832\n",
            "New Sample 82: Reconstruction Error = 32.8767\n",
            "New Sample 83: Reconstruction Error = 44.8166\n",
            "New Sample 84: Reconstruction Error = 29.2335\n",
            "New Sample 85: Reconstruction Error = 30.1303\n",
            "New Sample 86: Reconstruction Error = 58.5037\n",
            "New Sample 87: Reconstruction Error = 21.7036\n",
            "New Sample 88: Reconstruction Error = 33.5166\n",
            "New Sample 89: Reconstruction Error = 41.7587\n",
            "New Sample 90: Reconstruction Error = 41.0096\n",
            "New Sample 91: Reconstruction Error = 42.0266\n",
            "New Sample 92: Reconstruction Error = 22.5914\n",
            "New Sample 93: Reconstruction Error = 37.8085\n",
            "New Sample 94: Reconstruction Error = 42.4535\n",
            "New Sample 95: Reconstruction Error = 31.6211\n",
            "New Sample 96: Reconstruction Error = 33.3670\n",
            "New Sample 97: Reconstruction Error = 37.1367\n",
            "New Sample 98: Reconstruction Error = 49.2002\n",
            "New Sample 99: Reconstruction Error = 40.0308\n",
            "New Sample 100: Reconstruction Error = 33.1470\n",
            "New Sample 101: Reconstruction Error = 20.4333\n",
            "New Sample 102: Reconstruction Error = 34.3164\n",
            "New Sample 103: Reconstruction Error = 58.2700\n",
            "New Sample 104: Reconstruction Error = 41.0519\n",
            "New Sample 105: Reconstruction Error = 41.7198\n",
            "New Sample 106: Reconstruction Error = 40.6059\n",
            "New Sample 107: Reconstruction Error = 14.2691\n",
            "New Sample 108: Reconstruction Error = 39.7184\n",
            "New Sample 109: Reconstruction Error = 33.9337\n",
            "New Sample 110: Reconstruction Error = 19.3015\n",
            "New Sample 111: Reconstruction Error = 35.0448\n",
            "New Sample 112: Reconstruction Error = 55.8779\n",
            "New Sample 113: Reconstruction Error = 32.8666\n",
            "New Sample 114: Reconstruction Error = 38.0582\n",
            "New Sample 115: Reconstruction Error = 59.4328\n",
            "New Sample 116: Reconstruction Error = 10.1322\n",
            "New Sample 117: Reconstruction Error = 35.4931\n",
            "New Sample 118: Reconstruction Error = 40.2218\n",
            "New Sample 119: Reconstruction Error = 44.6029\n",
            "New Sample 120: Reconstruction Error = 50.3294\n",
            "New Sample 121: Reconstruction Error = 38.2425\n",
            "New Sample 122: Reconstruction Error = 41.6552\n",
            "New Sample 123: Reconstruction Error = 38.8107\n",
            "New Sample 124: Reconstruction Error = 34.3323\n",
            "New Sample 125: Reconstruction Error = 33.7636\n",
            "New Sample 126: Reconstruction Error = 33.4221\n",
            "New Sample 127: Reconstruction Error = 40.7840\n",
            "New Sample 128: Reconstruction Error = 33.6318\n",
            "New Sample 129: Reconstruction Error = 22.6459\n",
            "New Sample 130: Reconstruction Error = 28.6355\n",
            "New Sample 131: Reconstruction Error = 12.1745\n",
            "New Sample 132: Reconstruction Error = 19.9568\n",
            "New Sample 133: Reconstruction Error = 13.7919\n",
            "New Sample 134: Reconstruction Error = 14.5506\n",
            "New Sample 135: Reconstruction Error = 10.9188\n",
            "New Sample 136: Reconstruction Error = 26.9545\n",
            "New Sample 137: Reconstruction Error = 4.4482\n",
            "New Sample 138: Reconstruction Error = 5.6247\n",
            "New Sample 139: Reconstruction Error = 28.9000\n",
            "New Sample 140: Reconstruction Error = 11.8225\n",
            "New Sample 141: Reconstruction Error = 5.7589\n",
            "New Sample 142: Reconstruction Error = 28.9729\n",
            "New Sample 143: Reconstruction Error = 8.4687\n",
            "New Sample 144: Reconstruction Error = 29.5122\n",
            "New Sample 145: Reconstruction Error = 19.5135\n",
            "New Sample 146: Reconstruction Error = 22.5140\n",
            "New Sample 147: Reconstruction Error = 4.4606\n",
            "New Sample 148: Reconstruction Error = 24.5215\n",
            "New Sample 149: Reconstruction Error = 10.7525\n",
            "New Sample 150: Reconstruction Error = 12.8681\n",
            "New Sample 151: Reconstruction Error = 25.9729\n",
            "New Sample 152: Reconstruction Error = 6.0063\n",
            "New Sample 153: Reconstruction Error = 20.3743\n",
            "New Sample 154: Reconstruction Error = 16.1301\n",
            "New Sample 155: Reconstruction Error = 7.3032\n",
            "New Sample 156: Reconstruction Error = 28.3685\n",
            "New Sample 157: Reconstruction Error = 4.4046\n",
            "New Sample 158: Reconstruction Error = 27.6388\n",
            "New Sample 159: Reconstruction Error = 13.3448\n",
            "New Sample 160: Reconstruction Error = 8.6645\n",
            "New Sample 161: Reconstruction Error = 27.5504\n",
            "New Sample 162: Reconstruction Error = 11.6491\n",
            "New Sample 163: Reconstruction Error = 24.4598\n",
            "New Sample 164: Reconstruction Error = 7.7690\n",
            "New Sample 165: Reconstruction Error = 26.0401\n",
            "New Sample 166: Reconstruction Error = 18.5368\n",
            "New Sample 167: Reconstruction Error = 8.1302\n",
            "New Sample 168: Reconstruction Error = 20.7468\n",
            "New Sample 169: Reconstruction Error = 20.5400\n",
            "New Sample 170: Reconstruction Error = 9.1883\n",
            "New Sample 171: Reconstruction Error = 28.1433\n",
            "New Sample 172: Reconstruction Error = 30.2215\n",
            "New Sample 173: Reconstruction Error = 5.4427\n",
            "New Sample 174: Reconstruction Error = 16.2672\n",
            "New Sample 175: Reconstruction Error = 27.8742\n",
            "New Sample 176: Reconstruction Error = 5.3198\n",
            "New Sample 177: Reconstruction Error = 15.6545\n",
            "New Sample 178: Reconstruction Error = 25.1796\n",
            "New Sample 179: Reconstruction Error = 20.4319\n",
            "New Sample 180: Reconstruction Error = 20.3611\n",
            "New Sample 181: Reconstruction Error = 13.5467\n",
            "New Sample 182: Reconstruction Error = 27.9107\n",
            "New Sample 183: Reconstruction Error = 10.2253\n",
            "New Sample 184: Reconstruction Error = 12.1254\n",
            "New Sample 185: Reconstruction Error = 31.6949\n",
            "New Sample 186: Reconstruction Error = 5.9427\n",
            "New Sample 187: Reconstruction Error = 28.1585\n",
            "New Sample 188: Reconstruction Error = 14.2560\n",
            "New Sample 189: Reconstruction Error = 28.0813\n",
            "New Sample 190: Reconstruction Error = 3.5123\n",
            "New Sample 191: Reconstruction Error = 5.0348\n",
            "New Sample 192: Reconstruction Error = 28.0524\n",
            "New Sample 193: Reconstruction Error = 4.9723\n",
            "New Sample 194: Reconstruction Error = 32.0709\n",
            "New Sample 195: Reconstruction Error = 13.5250\n",
            "New Sample 196: Reconstruction Error = 35.8454\n",
            "New Sample 197: Reconstruction Error = 9.2976\n",
            "New Sample 198: Reconstruction Error = 30.8626\n",
            "New Sample 199: Reconstruction Error = 9.7031\n",
            "New Sample 200: Reconstruction Error = 23.9818\n",
            "New Sample 201: Reconstruction Error = 10.5079\n",
            "New Sample 202: Reconstruction Error = 10.4727\n",
            "New Sample 203: Reconstruction Error = 27.7440\n",
            "New Sample 204: Reconstruction Error = 5.7184\n",
            "New Sample 205: Reconstruction Error = 29.3167\n",
            "New Sample 206: Reconstruction Error = 28.5983\n",
            "New Sample 207: Reconstruction Error = 12.4174\n",
            "New Sample 208: Reconstruction Error = 28.1084\n",
            "New Sample 209: Reconstruction Error = 29.8290\n",
            "New Sample 210: Reconstruction Error = 11.4289\n",
            "New Sample 211: Reconstruction Error = 26.4859\n",
            "New Sample 212: Reconstruction Error = 13.7525\n",
            "New Sample 213: Reconstruction Error = 4.3434\n",
            "New Sample 214: Reconstruction Error = 9.2954\n",
            "New Sample 215: Reconstruction Error = 24.8963\n",
            "New Sample 216: Reconstruction Error = 14.5516\n",
            "New Sample 217: Reconstruction Error = 5.5360\n",
            "New Sample 218: Reconstruction Error = 28.6860\n",
            "New Sample 219: Reconstruction Error = 12.3179\n",
            "New Sample 220: Reconstruction Error = 5.8191\n",
            "New Sample 221: Reconstruction Error = 30.1752\n",
            "New Sample 222: Reconstruction Error = 3.9035\n",
            "New Sample 223: Reconstruction Error = 27.5787\n",
            "New Sample 224: Reconstruction Error = 28.3278\n",
            "New Sample 225: Reconstruction Error = 4.3877\n",
            "New Sample 226: Reconstruction Error = 28.3995\n",
            "New Sample 227: Reconstruction Error = 28.1662\n",
            "New Sample 228: Reconstruction Error = 9.9798\n",
            "New Sample 229: Reconstruction Error = 30.9831\n",
            "New Sample 230: Reconstruction Error = 28.2392\n",
            "New Sample 231: Reconstruction Error = 4.4437\n",
            "New Sample 232: Reconstruction Error = 5.7558\n",
            "New Sample 233: Reconstruction Error = 28.2750\n",
            "New Sample 234: Reconstruction Error = 6.9907\n",
            "New Sample 235: Reconstruction Error = 34.3178\n",
            "New Sample 236: Reconstruction Error = 4.7242\n",
            "New Sample 237: Reconstruction Error = 28.1981\n",
            "New Sample 238: Reconstruction Error = 16.2525\n",
            "New Sample 239: Reconstruction Error = 19.2829\n",
            "New Sample 240: Reconstruction Error = 30.8540\n",
            "New Sample 241: Reconstruction Error = 9.6897\n",
            "New Sample 242: Reconstruction Error = 28.4481\n",
            "New Sample 243: Reconstruction Error = 7.8418\n",
            "New Sample 244: Reconstruction Error = 33.8485\n",
            "New Sample 245: Reconstruction Error = 10.0493\n",
            "New Sample 246: Reconstruction Error = 28.1767\n",
            "New Sample 247: Reconstruction Error = 5.8225\n",
            "New Sample 248: Reconstruction Error = 27.7191\n",
            "New Sample 249: Reconstruction Error = 19.9935\n",
            "New Sample 250: Reconstruction Error = 14.3897\n",
            "New Sample 251: Reconstruction Error = 5.1502\n",
            "New Sample 252: Reconstruction Error = 28.2420\n",
            "New Sample 253: Reconstruction Error = 11.8378\n",
            "New Sample 254: Reconstruction Error = 28.9633\n",
            "New Sample 255: Reconstruction Error = 3.9468\n",
            "New Sample 256: Reconstruction Error = 29.0114\n",
            "New Sample 257: Reconstruction Error = 17.6459\n",
            "New Sample 258: Reconstruction Error = nan\n",
            "25.894620831374528\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
        ")\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# 1. CSV 파일 불러오기\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/data/reconstruction_errors.csv\")  # 같은 디렉토리에 있는 파일 사용\n",
        "\n",
        "# 2. 데이터 전처리\n",
        "errors = df[\"error\"].values\n",
        "labels = df[\"label\"].values\n",
        "\n",
        "# 3. 스케일링\n",
        "scaler = StandardScaler()\n",
        "errors_scaled = scaler.fit_transform(errors.reshape(-1, 1))\n",
        "\n",
        "# 4. 학습/테스트 데이터 분리\n",
        "X_train, X_test, y_train, y_test = train_test_split(errors_scaled, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# 5. 로지스틱 회귀 모델 학습\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# 6. 예측 및 평가\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "roc_auc = roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# 7. 평가 결과 출력\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall (Sensitivity): {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n",
        "\n",
        "# 8. 특정 Reconstruction Error에 대한 예측 확률 함수\n",
        "def predict_probabilities(reconstruction_error):\n",
        "    scaled_error = scaler.transform(np.array([[reconstruction_error]]))\n",
        "    probabilities = model.predict_proba(scaled_error)\n",
        "    human_prob, ai_prob = probabilities[0]\n",
        "    return human_prob, ai_prob\n",
        "\n",
        "# 9. 예시 사용\n",
        "test_error = 53.9091\n",
        "human_prob, ai_prob = predict_probabilities(test_error)\n",
        "\n",
        "print(f\"\\nReconstruction Error = {test_error}\")\n",
        "print(f\"Probability of Human: {human_prob:.2%}\")\n",
        "print(f\"Probability of AI: {ai_prob:.2%}\")\n"
      ],
      "metadata": {
        "id": "ciJ7WDDYVZ5e",
        "outputId": "58bf28c3-bcfb-4177-a208-07a720731aa5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8689\n",
            "Precision: 0.8889\n",
            "Recall (Sensitivity): 0.7273\n",
            "F1 Score: 0.8000\n",
            "\n",
            "Reconstruction Error = 53.9091\n",
            "Probability of Human: 17.10%\n",
            "Probability of AI: 82.90%\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}